{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f20c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52627b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (1.60.1)\n",
      "Collecting openai\n",
      "  Using cached openai-1.76.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/envs/DL/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Using cached openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.60.1\n",
      "    Uninstalling openai-1.60.1:\n",
      "      Successfully uninstalled openai-1.60.1\n",
      "Successfully installed openai-1.76.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f72ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "# import os\n",
    "# import openai\n",
    "# import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29bca4c",
   "metadata": {},
   "source": [
    "## Example 1 - Simple Tool-Free Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec62f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inductive reasoning  \n",
      "• Starts with specific observations, data, or cases.  \n",
      "• Looks for patterns or regularities among them.  \n",
      "• From those patterns, it infers a general rule, trend, or theory.  \n",
      "• Conclusion is probable, not guaranteed; new evidence can overturn it.  \n",
      "• Often called “bottom-up” reasoning.  \n",
      "Example:  \n",
      "– Swans you have seen so far are white → You infer “All swans are white.” (A single black swan can refute it.)\n",
      "\n",
      "Deductive reasoning  \n",
      "• Starts with one or more general principles, laws, or premises that are accepted as true.  \n",
      "• Applies these principles to a particular case.  \n",
      "• If the premises are true and the logic is valid, the conclusion must be true.  \n",
      "• Often called “top-down” reasoning.  \n",
      "Example:  \n",
      "– Premise 1: All mammals are warm-blooded.  \n",
      "– Premise 2: Whales are mammals.  \n",
      "– Conclusion: Therefore, whales are warm-blooded. (The conclusion is logically certain.)\n",
      "\n",
      "Key contrasts  \n",
      "1. Direction: Induction moves from specifics to generalities; deduction moves from generalities to specifics.  \n",
      "2. Strength of conclusion: Inductive conclusions are probable; deductive conclusions are necessary (given true premises).  \n",
      "3. Use: Induction is common in science for forming hypotheses and theories; deduction is common in mathematics, formal logic, and for testing hypotheses.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"o3\",\n",
    "    input=[{\"role\": \"user\", \"content\": \"What’s the difference between inductive and deductive reasoning?\"}]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c4319",
   "metadata": {},
   "source": [
    "## Example 2: Code + Math Problem Solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c431d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a Python function that solves quadratic equations and also explain the math behind it.\"\n",
    "response = client.responses.create(\n",
    "    model=\"o3\",\n",
    "    reasoning={\"effort\": \"high\"},\n",
    "    input=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5b9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a compact, self-contained implementation followed by a step-by-step explanation of the mathematics and a few practical notes.\n",
      "\n",
      "------------------------------------------------------------\n",
      "Python implementation\n",
      "------------------------------------------------------------\n",
      "\n",
      "```python\n",
      "import cmath          # handles both real and complex arithmetic\n",
      "\n",
      "def solve_quadratic(a: float, b: float, c: float):\n",
      "    \"\"\"\n",
      "    Returns the roots of a quadratic equation a·x² + b·x + c = 0.\n",
      "\n",
      "    The function always returns a tuple:\n",
      "        • two numbers (possibly complex) for a ≠ 0\n",
      "        • one number          for a == 0 and b ≠ 0   (degenerates to linear)\n",
      "    It raises ValueError if the equation has no finite solution\n",
      "    (e.g. a == b == 0 and c ≠ 0) or infinitely many solutions\n",
      "    (a == b == c == 0).\n",
      "    \"\"\"\n",
      "\n",
      "    # Degenerate cases ---------------------------------------------------\n",
      "    if a == 0:                       # not really quadratic\n",
      "        if b == 0:\n",
      "            if c == 0:\n",
      "                raise ValueError(\"Every real number is a solution (0 = 0).\")\n",
      "            raise ValueError(\"No solution (constant ≠ 0).\")\n",
      "        return (-c / b,)             # linear root packaged in a singleton\n",
      "\n",
      "    # Proper quadratic ---------------------------------------------------\n",
      "    discriminant = b*b - 4*a*c       # Δ = b² − 4ac\n",
      "    sqrt_disc   = cmath.sqrt(discriminant)\n",
      "\n",
      "    root1 = (-b + sqrt_disc) / (2*a)\n",
      "    root2 = (-b - sqrt_disc) / (2*a)\n",
      "\n",
      "    return (root1, root2)\n",
      "```\n",
      "\n",
      "Example use\n",
      "\n",
      "```python\n",
      ">>> solve_quadratic(1, 3, 2)      # x² + 3x + 2 = 0\n",
      "(-1+0j, -2+0j)\n",
      "\n",
      ">>> solve_quadratic(1, 2, 5)      # x² + 2x + 5 = 0\n",
      "((-1+2j), (-1-2j))\n",
      "\n",
      ">>> solve_quadratic(0, 4, -8)     # 4x - 8 = 0   (linear)\n",
      "(2.0,)\n",
      "```\n",
      "\n",
      "------------------------------------------------------------\n",
      "Why the code works – the mathematics\n",
      "------------------------------------------------------------\n",
      "\n",
      "1. The starting point  \n",
      "   A quadratic equation is any polynomial equation of degree two:\n",
      "\n",
      "        a·x² + b·x + c = 0        where a ≠ 0\n",
      "\n",
      "2. Completing the square  \n",
      "\n",
      "        a·x² + b·x + c = 0\n",
      "   Divide by a:\n",
      "        x² + (b/a)·x = –c/a\n",
      "   Add (b/2a)² to both sides:\n",
      "        x² + (b/a)·x + (b/2a)² = –c/a + (b/2a)²\n",
      "   The left side is now a perfect square:\n",
      "        (x + b/2a)² = (b² – 4ac) / 4a²\n",
      "\n",
      "3. Solving for x gives the quadratic formula\n",
      "\n",
      "        x = [ –b ± √(b² – 4ac) ] / (2a)\n",
      "\n",
      "   • The quantity Δ = b² – 4ac is called the discriminant.  \n",
      "   • Its sign tells you what kind of roots you get:\n",
      "\n",
      "     Δ > 0  → two distinct real roots  \n",
      "     Δ = 0  → one real root of multiplicity two  \n",
      "     Δ < 0  → two complex conjugate roots\n",
      "\n",
      "4. Numerical aspects captured in the code\n",
      "\n",
      "   • `cmath.sqrt` works for both positive and negative Δ, so the routine never\n",
      "     fails and will produce complex numbers automatically when needed.  \n",
      "   • Special handling of a = 0 turns the routine into a solver for the linear\n",
      "     equation b·x + c = 0.  \n",
      "   • Edge cases (no solution, infinitely many solutions) are signaled by\n",
      "     exceptions rather than silent failure.\n",
      "\n",
      "------------------------------------------------------------\n",
      "Practical tips\n",
      "------------------------------------------------------------\n",
      "\n",
      "• Floating-point equality checks: In production code you may want to replace\n",
      "  the exact comparisons `a == 0` or `b == 0` with `abs(a) < ε` where ε is a\n",
      "  small tolerance such as 1e-12.\n",
      "\n",
      "• Loss of significance: For very ill-conditioned inputs (|b| ≫ |a|, |c|)\n",
      "  one of the two roots can suffer catastrophic cancellation.  \n",
      "  Robust libraries (NumPy, SciPy) provide alternative formulas that mitigate\n",
      "  this, but for everyday-sized coefficients the standard formula is fine.\n",
      "\n",
      "• Real-only variant: If you prefer to raise an error instead of returning\n",
      "  complex roots, simply use `import math` and change\n",
      "  `sqrt_disc = math.sqrt(discriminant)`; `math.sqrt` will raise `ValueError`\n",
      "  when Δ < 0.\n",
      "\n",
      "That’s all there is to solving quadratics programmatically—grounded directly\n",
      "in the algebra taught in high-school mathematics.\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6107dc",
   "metadata": {},
   "source": [
    "## Example 3: Visual Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5597536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a “personal LLM-track” agenda pulled from every item in the photo whose title clearly mentions\n",
      " • LLM / Large-Language-Model,\n",
      " • “Large Foundation Model”, “Transformer”, “Generative-AI” panels that explicitly discuss LLM issues.\n",
      "\n",
      "Because the picture is blurry (and only shows end-times), I had to infer reasonable start-times and\n",
      "durations.  I’ve kept a uniform pattern—50-min talks / 90-min workshops—always leaving a 10-minute\n",
      "buffer so you can walk between rooms, grab water, or take notes.\n",
      "\n",
      "Verify exact rooms & official times with the conference app before the event.\n",
      "\n",
      "────────────────────────────────────────\n",
      "THURSDAY 24 APRIL  –  EXPO-TALK DAY\n",
      "────────────────────────────────────────\n",
      "09:00 – 09:50   Transformer Models: RL Research & Systematic Investing  \n",
      "09:50 – 10:00   BREAK (10 min)\n",
      "\n",
      "10:00 – 10:50   Human Attention: It’s NOT All You Need  \n",
      "10:50 – 11:00   BREAK (10 min)\n",
      "\n",
      "11:00 – 11:50   Generative AI: Understanding Large Foundation Models  \n",
      "11:50 – 12:00   BREAK (10 min)\n",
      "\n",
      "12:00 – 12:50   Auditing AI & LLM Systems: A Holistic Approach  \n",
      "12:50 – 14:00   LUNCH (self-organised)\n",
      "\n",
      "────────────────────────────────────────\n",
      "FRIDAY 25 APRIL  –  LLM-ENGINEERING PANELS\n",
      "────────────────────────────────────────\n",
      "09:00 – 09:40   Leveraging Automated LLMs for Shopify’s Global Catalogue  \n",
      "09:40 – 09:50   BREAK (10 min)\n",
      "\n",
      "09:50 – 10:30   LLM Platforms & Efficient Infrastructure for Post-Training  \n",
      "10:30 – 10:40   BREAK (10 min)\n",
      "\n",
      "10:40 – 11:20   Benchmarking LLM Benchmarks: Making AI Work for the Real World  \n",
      "11:20 – 11:30   BREAK (10 min)\n",
      "\n",
      "11:30 – 12:10   Flash-Attention Deep-Dive for Real-Time LLMs  \n",
      "12:10 – 13:30   LUNCH (self-organised)\n",
      "\n",
      "────────────────────────────────────────\n",
      "SATURDAY 26 APRIL  –  LLM WORKSHOP MARATHON\n",
      "────────────────────────────────────────\n",
      "09:00 – 10:30   Hallucination & De-Hallucination in Foundation Models  \n",
      "10:30 – 10:40   BREAK (10 min)\n",
      "\n",
      "10:40 – 12:10   Direct Preference Optimisation (DPO) Without Human Labels  \n",
      "12:10 – 13:00   LUNCH (self-organised)\n",
      "\n",
      "13:00 – 14:30   LLMs for Genomics Explorations (MLGen)  \n",
      "14:30 – 14:40   BREAK (10 min)\n",
      "\n",
      "14:40 – 16:10   GenAI Watermarking for LLM-Safety (WMAR)  \n",
      "16:10 – 16:20   BREAK (10 min)\n",
      "\n",
      "16:20 – 17:50   Sparsity in LLMs & Mixture-of-Experts: Opportunities & Challenges  \n",
      "17:50 – 18:00   BREAK (10 min)\n",
      "\n",
      "────────────────────────────────────────\n",
      "SUNDAY 27 APRIL  –  OPTIONAL\n",
      "────────────────────────────────────────\n",
      "09:00 – 10:30   Large-Scale Ontological Representations of Life (LAMR) – *only partly LLM-related*  \n",
      "10:30 – 10:40   BREAK (10 min)\n",
      "\n",
      "You can skip Sunday if you want a rest day; no other clear LLM items appear in the photo.\n",
      "\n",
      "────────────────────────────────────────\n",
      "MONDAY 28 APRIL\n",
      "────────────────────────────────────────\n",
      "No LLM-specific events listed in the provided image.\n",
      "\n",
      "Have a great conference—this schedule keeps LLM content front-and-center while guaranteeing you at\n",
      "least 10 minutes between every session!\n"
     ]
    }
   ],
   "source": [
    "# Example 3.1\n",
    "\n",
    "import base64, mimetypes, pathlib\n",
    "from openai import OpenAI\n",
    "\n",
    "def to_data_url(path: str) -> str:\n",
    "    mime = mimetypes.guess_type(path)[0] or \"application/octet-stream\"\n",
    "    data = pathlib.Path(path).read_bytes()\n",
    "    b64  = base64.b64encode(data).decode()\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "prompt = (\n",
    "    \"Create a schedule using this blurry conference photo. \"\n",
    "    \"Ensure 10-minute gaps between talks and include all talks related to LLMs.\"\n",
    ")\n",
    "\n",
    "image_path   = \"/Users/aashidutt/Desktop/o3demo/Schedule.png\"\n",
    "image_url    = to_data_url(image_path)          # ⇦ make it a data-URL\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"o3\",                                  \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\",      \"text\": prompt },\n",
    "                { \"type\": \"image_url\", \"image_url\": { \"url\": image_url } }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    # temperature=0.3,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79a2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=3029, prompt_tokens=1007, total_tokens=4036, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2112, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c535357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a clean, “LLM-track” agenda extracted from the conference board you sent.  \n",
      "• Only sessions whose title explicitly mentions “LLM”, “Large(-scale) Foundation Model”, “Large Language Model”, “Gen-AI” or whose focus is the evaluation / auditing / fine-tuning of those models are kept.  \n",
      "• Everything is placed in 40-minute talk blocks with a mandatory 10-minute gap before the next block (so you can move rooms, grab water, etc.).  \n",
      "• Times are given in the conference’s local time-zone.  If a listed session actually lasts longer than 40 min, you can stay; the schedule merely guarantees you never have to sprint between rooms.\n",
      "\n",
      "────────────────────────\n",
      "THURSDAY – 24 APRIL 2025\n",
      "────────────────────────\n",
      "09:00–09:40  Creating, Measuring & Understanding Large Foundation Models  \n",
      "09:40–09:50  Break\n",
      "09:50–10:30  Auditing Gen-AI & Achieving Audit with Foundation Models and LLMs  \n",
      "10:30–10:40  Break  \n",
      "\n",
      "────────────────────────\n",
      "FRIDAY – 25 APRIL 2025\n",
      "────────────────────────\n",
      "09:00–09:40  Leveraging Advanced LLMs for Shopify’s Global Catalogue  \n",
      "09:40–09:50  Break\n",
      "09:50–10:30  Evaluating LLM Benchmarks: Making AI Work for Real-World Impact  \n",
      "10:30–10:40  Break  \n",
      "\n",
      "────────────────────────\n",
      "SATURDAY – 26 APRIL 2025  (Workshops)\n",
      "────────────────────────\n",
      "09:00–09:40  Fine-Tuning & Adaptation in Foundation Models  \n",
      "09:40–09:50  Break\n",
      "09:50–10:30  Building / Opening Foundation Models Without Human Annotations  \n",
      "10:30–10:40  Break\n",
      "10:40–11:20  Heuristic Prompt Weights as a New Data Modality  \n",
      "11:20–11:30  Break\n",
      "11:30–12:10  Scarcity in LLMs – Deep-Dive into Future Evaluation, Benchmarking & Inference  \n",
      "12:10–12:20  Break\n",
      "12:20–13:00  GenAI Watermarking Workshop (WAMR ’25)  \n",
      "13:00–13:10  Break\n",
      "13:10–13:50  The Future of Evaluation & Attribution in Foundation Models  \n",
      "13:50–14:00  Break  \n",
      "\n",
      "────────────────────────\n",
      "SUNDAY – 27 APRIL 2025  (Workshop)\n",
      "────────────────────────\n",
      "09:00–09:40  Large-Morphological Representations of Life (LML)  \n",
      "09:40–09:50  Break  \n",
      "\n",
      "That’s every LLM-related session visible in the photo, with guaranteed 10-minute breathing spaces.  Enjoy the conference!\n"
     ]
    }
   ],
   "source": [
    "# Example 3.2\n",
    "\n",
    "import base64, mimetypes, pathlib\n",
    "from openai import OpenAI\n",
    "\n",
    "def to_data_url(path: str) -> str:\n",
    "    mime = mimetypes.guess_type(path)[0] or \"application/octet-stream\"\n",
    "    data = pathlib.Path(path).read_bytes()\n",
    "    b64  = base64.b64encode(data).decode()\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "prompt = (\n",
    "    \"Create a schedule using this blurry conference photo. \"\n",
    "    \"Ensure 10-minute gaps between talks and include all talks related to LLMs.\"\n",
    ")\n",
    "\n",
    "image_path   = \"/Users/aashidutt/Desktop/o3demo/Schedule.png\"\n",
    "image_url    = to_data_url(image_path)          \n",
    "\n",
    "limit_token_response = client.chat.completions.create(\n",
    "    model=\"o3\",                                  \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\",      \"text\": prompt },\n",
    "                { \"type\": \"image_url\", \"image_url\": { \"url\": image_url } }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_completion_tokens=3000,\n",
    ")\n",
    "\n",
    "print(limit_token_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6bb0b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=2746, prompt_tokens=1007, total_tokens=3753, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=2112, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "print(limit_token_response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e79706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. The sphere that’s the same size as the metallic cube is a shiny, reflective red, while the small red sphere on the left is matte. They are made of different materials.\n"
     ]
    }
   ],
   "source": [
    "# Example 3.3\n",
    "\n",
    "import base64, mimetypes, pathlib\n",
    "\n",
    "def to_data_url(path: str) -> str:\n",
    "    mime = mimetypes.guess_type(path)[0] or \"application/octet-stream\"\n",
    "    data = pathlib.Path(path).read_bytes()\n",
    "    b64  = base64.b64encode(data).decode()\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "prompt = (\n",
    "    \"There is a sphere with the same size as the metal cube; is it made of the same material as the small red sphere?\"\n",
    ")\n",
    "\n",
    "image_path   = \"/Users/aashidutt/Desktop/o3demo/Image1.png\"\n",
    "image_url    = to_data_url(image_path)          \n",
    "\n",
    "limit_token_response = client.chat.completions.create(\n",
    "    model=\"o3\",                                  \n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\",      \"text\": prompt },\n",
    "                { \"type\": \"image_url\", \"image_url\": { \"url\": image_url } }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_completion_tokens=3000,\n",
    ")\n",
    "\n",
    "print(limit_token_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cea97",
   "metadata": {},
   "source": [
    "## Example 4: Code Refactoring Task (React)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca27a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const books = [\n",
      "    { title: 'Dune', category: 'fiction', id: 1 },\n",
      "    { title: 'Frankenstein', category: 'fiction', id: 2 },\n",
      "    { title: 'Moneyball', category: 'nonfiction', id: 3 },\n",
      "];\n",
      "\n",
      "export default function BookList() {\n",
      "    const listItems = books.map(book =>\n",
      "        <li\n",
      "            key={book.id}\n",
      "            style={book.category === 'nonfiction' ? { color: 'red' } : {}}\n",
      "        >\n",
      "            {book.title}\n",
      "        </li>\n",
      "    );\n",
      "\n",
      "    return (\n",
      "        <ul>{listItems}</ul>\n",
      "    );\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Instructions:\n",
    "- Given the React component below, change it so that nonfication books have red\n",
    "  text. \n",
    "- Return only the code in your reply\n",
    "- Do not include any additional formatting, such as markdown code blocks\n",
    "- For formatting, use four space tabs, and do not allow any lines of code to \n",
    "  exceed 80 columns\n",
    "\n",
    "const books = [\n",
    "  { title: 'Dune', category: 'fiction', id: 1 },\n",
    "  { title: 'Frankenstein', category: 'fiction', id: 2 },\n",
    "  { title: 'Moneyball', category: 'nonfiction', id: 3 },\n",
    "];\n",
    "\n",
    "export default function BookList() {\n",
    "  const listItems = books.map(book =>\n",
    "    <li>\n",
    "      {book.title}\n",
    "    </li>\n",
    "  );\n",
    "\n",
    "  return (\n",
    "    <ul>{listItems}</ul>\n",
    "  );\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o3\",\n",
    "    reasoning={\"effort\": \"medium\", \"summary\": \"detailed\"}, #Supported values are: 'concise', 'detailed', and 'auto'.\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "963e9157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseUsage(input_tokens=186, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=1552, output_tokens_details=OutputTokensDetails(reasoning_tokens=1408), total_tokens=1738)\n"
     ]
    }
   ],
   "source": [
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ccc0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
